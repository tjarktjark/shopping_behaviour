{"cells": [{"metadata": {}, "cell_type": "code", "source": "### Modelling ###", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "import pandas as pd\nfrom sklearn.metrics import f1_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nimport pickle\n\nimport types\nfrom botocore.client import Config\nimport ibm_boto3", "execution_count": 13, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "def __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share the notebook.\nclient_3b08f636aa4c4bc58b03e36105622462 = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='EI06iPS11MRoHQiLAPwMFIukCpW_Yx5PqbVhI0FSYqjZ',\n    ibm_auth_endpoint=\"https://iam.eu-de.bluemix.net/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3.eu-geo.objectstorage.service.networklayer.com')\n\nbody = client_3b08f636aa4c4bc58b03e36105622462.get_object(Bucket='courserabadges-donotdelete-pr-72y9f6bzbckngj',Key='online_shoppers_intention_eng.csv')['Body']\nbody_tf = client_3b08f636aa4c4bc58b03e36105622462.get_object(Bucket='courserabadges-donotdelete-pr-72y9f6bzbckngj',Key='online_shoppers_intention_eng_tf.csv')['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n\ndf = pd.read_csv(body)\ndf_tf = pd.read_csv(body_tf)", "execution_count": 2, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# deep neural network\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\n\n# create model\ndef create_NN():\n    model = Sequential()\n    model.add(Dense(50, input_dim=74, activation='relu'))\n    model.add(Dropout(rate=0.4))\n    model.add(Dense(80, input_dim=50, activation='relu'))\n    model.add(Dense(50, input_dim=50, activation='relu'))\n    model.add(Dense(1, activation='sigmoid'))\n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n    return model\n\nmodels = {\n    'LogisticRegression': LogisticRegression(solver='lbfgs', max_iter = 500),\n    'GradientBoosting': GradientBoostingClassifier(), \n    'RandomForest': RandomForestClassifier(),\n    'NN': KerasClassifier(build_fn=create_NN, epochs=20, batch_size=10, verbose=0)\n}\nmodels = {\n    'NN': KerasClassifier(build_fn=create_NN, epochs=10, batch_size=100, verbose=1)\n}\n\nmodels = {\n    'LogisticRegression': LogisticRegression(solver='lbfgs', max_iter = 500)\n}\n\nfeature_sets = {'data': df, 'df_tf': df_tf}", "execution_count": 3, "outputs": [{"output_type": "stream", "text": "Using TensorFlow backend.\n", "name": "stderr"}]}, {"metadata": {}, "cell_type": "code", "source": "results = list()\nfor data_name, data in feature_sets.items():\n    X = data.iloc[:,:-1]\n    y = data.iloc[:,-1]\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n    for model_name, model in models.items():\n        model.fit(X_train, y_train)\n        y_pred = model.predict(X_test)\n        accuracy = model.score(X_test, y_test)\n        f1 = f1_score(y_true=y_test, y_pred=y_pred)\n        results.append([data_name, model_name, model, f1, accuracy])\n        ", "execution_count": 4, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "for result in results:\n    print(result)", "execution_count": 5, "outputs": [{"output_type": "stream", "text": "['data', 'LogisticRegression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=500, multi_class='warn',\n          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n          tol=0.0001, verbose=0, warm_start=False), 0.5097588978185994, 0.8841248303934871]\n['df_tf', 'LogisticRegression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=500, multi_class='warn',\n          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n          tol=0.0001, verbose=0, warm_start=False), 0.6039215686274509, 0.8903663500678426]\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "clf = results[1][2]", "execution_count": 6, "outputs": []}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "#result = zip(df.columns, clf.feature_importances_)\n#result = sorted(result, key=lambda x: x[1], reverse=True)\n#result[:10]", "execution_count": 7, "outputs": [{"output_type": "error", "ename": "AttributeError", "evalue": "'LogisticRegression' object has no attribute 'feature_importances_'", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)", "\u001b[0;32m<ipython-input-7-54e5944cd3fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;31mAttributeError\u001b[0m: 'LogisticRegression' object has no attribute 'feature_importances_'"]}]}, {"metadata": {}, "cell_type": "code", "source": "# concentrate feature eng on page values, multiply with others for example...", "execution_count": 8, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "deployment_model = results[0][2]\nfinal_model = pickle.dumps(deployment_model)\ninfo = client_3b08f636aa4c4bc58b03e36105622462.put_object(Bucket='courserabadges-donotdelete-pr-72y9f6bzbckngj',Key='final_model.pkl', Body=final_model)", "execution_count": 23, "outputs": [{"output_type": "execute_result", "execution_count": 23, "data": {"text/plain": "{'ResponseMetadata': {'RequestId': 'e802703c-f956-4a96-9a58-d937975912f1',\n  'HostId': '',\n  'HTTPStatusCode': 200,\n  'HTTPHeaders': {'date': 'Mon, 11 May 2020 09:41:18 GMT',\n   'x-clv-request-id': 'e802703c-f956-4a96-9a58-d937975912f1',\n   'server': 'Cleversafe/3.14.11.35',\n   'x-clv-s3-version': '2.5',\n   'x-amz-request-id': 'e802703c-f956-4a96-9a58-d937975912f1',\n   'etag': '\"140ca2bdfbd7ea9e1de00f7444cf58b0\"',\n   'content-length': '0'},\n  'RetryAttempts': 0},\n 'ETag': '\"140ca2bdfbd7ea9e1de00f7444cf58b0\"'}"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.6", "language": "python"}, "language_info": {"name": "python", "version": "3.6.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}