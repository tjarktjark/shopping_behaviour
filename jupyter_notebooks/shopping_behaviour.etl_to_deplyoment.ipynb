{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online Shopping Behaviour / Intention Prediction\n",
    "#### Tjark Petersen, May 2020\n",
    "\n",
    "In this notebook I apply preprocessing and feature engineering,train several models (standard ML + ANN), select a suitable model and store it for deployment. I use scikit's piepline module to makes sure the same processing is applied to different sets of the data. I store the final pripeline in the \"deployment\" folder. In the same folder, I set up a simple flask-based API to deploy the final pipeline. The files allow to run the app a) in a docker container, b) in IBM Cloud Foundry and c) in AWS Beanstalk.\n",
    "\n",
    "<img src=\"pipeline.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "\n",
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Administrative</th>\n",
       "      <th>Administrative_Duration</th>\n",
       "      <th>Informational</th>\n",
       "      <th>Informational_Duration</th>\n",
       "      <th>ProductRelated</th>\n",
       "      <th>ProductRelated_Duration</th>\n",
       "      <th>BounceRates</th>\n",
       "      <th>ExitRates</th>\n",
       "      <th>PageValues</th>\n",
       "      <th>SpecialDay</th>\n",
       "      <th>Month</th>\n",
       "      <th>OperatingSystems</th>\n",
       "      <th>Browser</th>\n",
       "      <th>Region</th>\n",
       "      <th>TrafficType</th>\n",
       "      <th>VisitorType</th>\n",
       "      <th>Weekend</th>\n",
       "      <th>Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>627.500000</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Administrative  Administrative_Duration  Informational  \\\n",
       "0             0.0                      0.0            0.0   \n",
       "1             0.0                      0.0            0.0   \n",
       "2             0.0                     -1.0            0.0   \n",
       "3             0.0                      0.0            0.0   \n",
       "4             0.0                      0.0            0.0   \n",
       "\n",
       "   Informational_Duration  ProductRelated  ProductRelated_Duration  \\\n",
       "0                     0.0             1.0                 0.000000   \n",
       "1                     0.0             2.0                64.000000   \n",
       "2                    -1.0             1.0                -1.000000   \n",
       "3                     0.0             2.0                 2.666667   \n",
       "4                     0.0            10.0               627.500000   \n",
       "\n",
       "   BounceRates  ExitRates  PageValues  SpecialDay Month  OperatingSystems  \\\n",
       "0         0.20       0.20         0.0         0.0   Feb                 1   \n",
       "1         0.00       0.10         0.0         0.0   Feb                 2   \n",
       "2         0.20       0.20         0.0         0.0   Feb                 4   \n",
       "3         0.05       0.14         0.0         0.0   Feb                 3   \n",
       "4         0.02       0.05         0.0         0.0   Feb                 3   \n",
       "\n",
       "   Browser  Region  TrafficType        VisitorType  Weekend  Revenue  \n",
       "0        1       1            1  Returning_Visitor    False    False  \n",
       "1        2       1            2  Returning_Visitor    False    False  \n",
       "2        1       9            3  Returning_Visitor    False    False  \n",
       "3        2       2            4  Returning_Visitor    False    False  \n",
       "4        3       1            4  Returning_Visitor     True    False  "
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../files/online_shoppers_intention.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([   2,    6,    7,   16,   21,   24,   49,   50,   64,  132,  140,\n",
      "             181,  182,  252,  383,  532,  540,  562,  591,  638, 2046, 2052,\n",
      "            2061, 4799, 4915, 5095, 5096, 5107, 5124, 6260, 7210, 8052, 8636],\n",
      "           dtype='int64')\n",
      "Int64Index([   2,    6,    7,   16,   21,   24,   49,   50,   64,  132,  140,\n",
      "             181,  182,  252,  383,  532,  540,  562,  591,  638, 2046, 2052,\n",
      "            2061, 4799, 4915, 5095, 5096, 5107, 5124, 6260, 7210, 8052, 8636],\n",
      "           dtype='int64')\n",
      "Int64Index([   2,    6,    7,   16,   21,   24,   49,   50,   64,  132,  140,\n",
      "             181,  182,  252,  383,  532,  540,  562,  591,  638, 2046, 2052,\n",
      "            2061, 4799, 4915, 5095, 5096, 5107, 5124, 6260, 7210, 8052, 8636],\n",
      "           dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "# delete the duration -1 cases\n",
    "print(df[df.Administrative_Duration == -1].index)\n",
    "print(df[df.Informational_Duration == -1].index)\n",
    "print(df[df.ProductRelated_Duration == -1].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete these 33 cases \n",
    "df = df[df.Administrative_Duration != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binarize the label\n",
    "df['Revenue'] = df['Revenue'].apply(lambda x: 1 if (x is True) else 0)\n",
    "\n",
    "# split the data into train and test set\n",
    "X=df.iloc[:,:-1]\n",
    "y=df.iloc[:,-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "561"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custum transformation for numerical data\n",
    "\n",
    "class SkewnessTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__( self):\n",
    "        self.name = 'numerical features'\n",
    "        \n",
    "    def feature_transform(self, df, func, add, columns=None):\n",
    "        \n",
    "        if columns is not None:\n",
    "            df_temp = df[columns].astype('float64')\n",
    "        else:\n",
    "            df_temp = df.astype('float64')\n",
    "        df_transformed = pd.DataFrame(df_temp.apply(lambda x: func(x+add)), columns = df_temp.columns)\n",
    "        return df_transformed.values\n",
    "        \n",
    "    def fit(self, X, y = None):\n",
    "        return self \n",
    "\n",
    "    def transform(self, X, y = None):\n",
    "        X = self.feature_transform(df=X, func=np.log, add=0.001)\n",
    "        return X\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.fit(X, y).transform(X)\n",
    "    \n",
    "\n",
    "class InteractionTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__( self):\n",
    "        self.name = 'interactions of numerical features'\n",
    "        \n",
    "    def add_interaction(self, df, col_1, col_2):\n",
    "        name = col_1 + col_2\n",
    "        df[name] = df[col_1] * df[col_2]\n",
    "        return df\n",
    "    \n",
    "    def add_time_feature(self, df, col_1):\n",
    "        name = col_1 + '_time_share'\n",
    "        df[name] = df[col_1]/(df['Informational_Duration'] + df['Administrative_Duration'] + df['ProductRelated_Duration'] + 1)\n",
    "        return df\n",
    "        \n",
    "    def fit(self, X, y = None):\n",
    "        return self \n",
    "\n",
    "    def transform(self, X, y = None):\n",
    "        X = self.add_interaction(df=X, col_1='Administrative', col_2='PageValues')\n",
    "        X = self.add_time_feature(df=X, col_1='Informational_Duration')\n",
    "        X = self.add_time_feature(df=X, col_1='Administrative_Duration')\n",
    "        X = self.add_time_feature(df=X, col_1='ProductRelated_Duration')\n",
    "        return X.values\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.fit(X, y).transform(X)\n",
    "\n",
    "# currently not in use  \n",
    "class CategoricalTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__( self):\n",
    "        self.name = 'categorical features'\n",
    "    \n",
    "    def fit(self, X, y = None):\n",
    "        return self \n",
    "\n",
    "    def transform(self, X, y = None):\n",
    "        # X = self.get_binary_weekend(df=X)\n",
    "        return self\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.fit(X, y).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cat_cols = ['Month', 'OperatingSystems', 'Browser', 'Region', 'TrafficType', 'VisitorType', 'Weekend']\n",
    "num_cols = ['Administrative',\n",
    "             'Administrative_Duration',\n",
    "             'Informational',\n",
    "             'Informational_Duration',\n",
    "             'ProductRelated',\n",
    "             'ProductRelated_Duration',\n",
    "             'BounceRates',\n",
    "             'ExitRates',\n",
    "             'PageValues',\n",
    "             'SpecialDay']\n",
    "label_col = ['Revenue']\n",
    "\n",
    "categorical_pipeline = Pipeline( steps = [('one_hot_encoder', OneHotEncoder(handle_unknown='ignore') )])\n",
    "\n",
    "\n",
    "numerical_pipeline = Pipeline( steps = [('median_imputer', SimpleImputer(missing_values=np.nan, strategy='median') ),\n",
    "                                        ('standardscaler', StandardScaler() )] )\n",
    "\n",
    "numerical_pipeline_log = Pipeline( steps = [ ('log_transformer', SkewnessTransformer() ),\n",
    "                                             ('median_imputer', SimpleImputer(missing_values=np.nan, strategy='median') ),\n",
    "                                             ('standardscaler', StandardScaler() )] )\n",
    "\n",
    "numerical_pipeline_inter = Pipeline( steps = [ ('interaction_transformer', InteractionTransformer() ),\n",
    "                                             ('median_imputer', SimpleImputer(missing_values=np.nan, strategy='median') ),\n",
    "                                             ('standardscaler', StandardScaler() )] )\n",
    "                                                        \n",
    "plain_pipeline = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_pipeline, num_cols),\n",
    "        ('cat', categorical_pipeline, cat_cols)])\n",
    "\n",
    "log_pipeline = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_pipeline_log, num_cols),\n",
    "        ('cat', categorical_pipeline, cat_cols)])\n",
    "\n",
    "inter_pipeline = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_pipeline_inter, num_cols),\n",
    "        ('cat', categorical_pipeline, cat_cols)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create NN model\n",
    "def create_NN():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(70, input_dim=75, activation='relu'))\n",
    "    model.add(Dropout(rate=0.4))\n",
    "    model.add(Dense(80, activation='relu'))\n",
    "    model.add(Dropout(rate=0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# models\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(solver='lbfgs', max_iter = 500),\n",
    "    'GradientBoosting': GradientBoostingClassifier(), \n",
    "    'RandomForest': RandomForestClassifier(),\n",
    "    'NN': KerasClassifier(build_fn=create_NN, epochs=10, batch_size=30, verbose=0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_pipeline(processing, estimator):\n",
    "    full_pipeline = Pipeline( steps = [ ( 'preprocessor', processing), ( 'model', estimator ) ] )\n",
    "    return full_pipeline\n",
    "\n",
    "feature_eng_options = {\n",
    "    'plain': plain_pipeline,\n",
    "    'log_transformed': log_pipeline,\n",
    "    #'with_interaction': inter_pipeline\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------\n",
      "Train Accuracy LogisticRegression plain 0.883466945509469\n",
      "Test Accuracy LogisticRegression plain 0.891869918699187\n",
      "Test F1 LogisticRegression plain 0.5501691093573844\n",
      "Test Precision LogisticRegression plain 0.7484662576687117\n",
      "Test Recall LogisticRegression plain 0.43493761140819964\n",
      "Test AUC LogisticRegression plain 0.7043655778357715\n",
      "---------------\n",
      "Train Accuracy GradientBoosting plain 0.9183222958057395\n",
      "Test Accuracy GradientBoosting plain 0.910840108401084\n",
      "Test F1 GradientBoosting plain 0.686964795432921\n",
      "Test Precision GradientBoosting plain 0.736734693877551\n",
      "Test Recall GradientBoosting plain 0.64349376114082\n",
      "Test AUC GradientBoosting plain 0.8011332659970639\n",
      "---------------\n",
      "Train Accuracy RandomForest plain 0.9901243174160567\n",
      "Test Accuracy RandomForest plain 0.8997289972899729\n",
      "Test F1 RandomForest plain 0.5960698689956332\n",
      "Test Precision RandomForest plain 0.7690140845070422\n",
      "Test Recall RandomForest plain 0.48663101604278075\n",
      "Test AUC RandomForest plain 0.7302122801530618\n",
      "---------------\n",
      "Train Accuracy NN plain 0.9100732207298279\n",
      "Test Accuracy NN plain 0.9029810428619385\n",
      "Test F1 NN plain 0.6517509727626458\n",
      "Test Precision NN plain 0.7173447537473233\n",
      "Test Recall NN plain 0.5971479500891266\n",
      "Test AUC NN plain 0.7774809740857905\n",
      "---------------\n",
      "Train Accuracy LogisticRegression log_transformed 0.89775763913094\n",
      "Test Accuracy LogisticRegression log_transformed 0.9021680216802168\n",
      "Test F1 LogisticRegression log_transformed 0.6571699905033239\n",
      "Test Precision LogisticRegression log_transformed 0.7032520325203252\n",
      "Test Recall LogisticRegression log_transformed 0.6167557932263814\n",
      "Test AUC LogisticRegression log_transformed 0.7850477591890935\n",
      "---------------\n",
      "Train Accuracy GradientBoosting log_transformed 0.9183222958057395\n",
      "Test Accuracy GradientBoosting log_transformed 0.9102981029810298\n",
      "Test F1 GradientBoosting log_transformed 0.6850618458610847\n",
      "Test Precision GradientBoosting log_transformed 0.7346938775510204\n",
      "Test Recall GradientBoosting log_transformed 0.6417112299465241\n",
      "Test AUC GradientBoosting log_transformed 0.800082204938107\n",
      "---------------\n",
      "Train Accuracy RandomForest log_transformed 0.9908214244219821\n",
      "Test Accuracy RandomForest log_transformed 0.8959349593495934\n",
      "Test F1 RandomForest log_transformed 0.5704697986577181\n",
      "Test Precision RandomForest log_transformed 0.7657657657657657\n",
      "Test Recall RandomForest log_transformed 0.45454545454545453\n",
      "Test AUC RandomForest log_transformed 0.7148086812516343\n",
      "---------------\n",
      "Train Accuracy NN log_transformed 0.9090275168418884\n",
      "Test Accuracy NN log_transformed 0.9070460796356201\n",
      "Test F1 NN log_transformed 0.6803355079217148\n",
      "Test Precision NN log_transformed 0.712890625\n",
      "Test Recall NN log_transformed 0.6506238859180036\n",
      "Test AUC NN log_transformed 0.8018220100730957\n"
     ]
    }
   ],
   "source": [
    "fitted_models = []\n",
    "for preprocessor_name, preprocessor in feature_eng_options.items():\n",
    "    for model_name, model in models.items():\n",
    "        full_pipeline = get_full_pipeline(processing=preprocessor, estimator=model)\n",
    "        full_pipeline.fit(X_train, y_train)\n",
    "        y_pred = full_pipeline.predict(X_test)\n",
    "        print('---------------')\n",
    "        print('Train Accuracy', model_name, preprocessor_name, full_pipeline.score(X_train, y_train))\n",
    "        print('Test Accuracy', model_name, preprocessor_name, full_pipeline.score(X_test, y_test))\n",
    "        print('Test F1', model_name, preprocessor_name, f1_score(y_true=y_test, y_pred=y_pred))\n",
    "        print('Test Precision', model_name, preprocessor_name, precision_score(y_true=y_test, y_pred=y_pred))\n",
    "        print('Test Recall', model_name, preprocessor_name, recall_score(y_true=y_test, y_pred=y_pred))\n",
    "        print('Test AUC', model_name, preprocessor_name, roc_auc_score(y_true=y_test, y_score=y_pred))\n",
    "        fitted_models.append({'model_name': model_name, 'preprocessor_name': preprocessor_name, 'fitted_pipeline': full_pipeline})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model Selection & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_name': 'GradientBoosting', 'preprocessor_name': 'plain', 'fitted_pipeline': Pipeline(memory=None,\n",
      "         steps=[('preprocessor',\n",
      "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
      "                                   sparse_threshold=0.3,\n",
      "                                   transformer_weights=None,\n",
      "                                   transformers=[('num',\n",
      "                                                  Pipeline(memory=None,\n",
      "                                                           steps=[('median_imputer',\n",
      "                                                                   SimpleImputer(add_indicator=False,\n",
      "                                                                                 copy=True,\n",
      "                                                                                 fill_value=None,\n",
      "                                                                                 missing_values=nan,\n",
      "                                                                                 strategy='median',\n",
      "                                                                                 verbose=0)),\n",
      "                                                                  ('standardscaler',\n",
      "                                                                   StandardScaler(copy...\n",
      "                                            learning_rate=0.1, loss='deviance',\n",
      "                                            max_depth=3, max_features=None,\n",
      "                                            max_leaf_nodes=None,\n",
      "                                            min_impurity_decrease=0.0,\n",
      "                                            min_impurity_split=None,\n",
      "                                            min_samples_leaf=1,\n",
      "                                            min_samples_split=2,\n",
      "                                            min_weight_fraction_leaf=0.0,\n",
      "                                            n_estimators=100,\n",
      "                                            n_iter_no_change=None,\n",
      "                                            presort='auto', random_state=None,\n",
      "                                            subsample=1.0, tol=0.0001,\n",
      "                                            validation_fraction=0.1, verbose=0,\n",
      "                                            warm_start=False))],\n",
      "         verbose=False)}\n"
     ]
    }
   ],
   "source": [
    "# select best model and preprocessing\n",
    "model_index = 1\n",
    "print(fitted_models[model_index])\n",
    "final_pipeline = fitted_models[model_index].get('fitted_pipeline')\n",
    "# take care // why is the re-fit necessary? \n",
    "final_pipeline = final_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9183222958057395, 0.910840108401084)"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train vs test set accuarcy\n",
    "final_pipeline.score(X=X_train, y=y_train), final_pipeline.score(X=X_test, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params = {\n",
    "    \"model__loss\":[\"deviance\"],\n",
    "    \"model__learning_rate\": [0.01, 0.05, 0.1, 0.2],\n",
    "    \"model__min_samples_split\": np.linspace(0.1, 0.5, 3),\n",
    "    \"model__min_samples_leaf\": np.linspace(0.1, 0.5, 3),\n",
    "    \"model__max_depth\":[3,5,8],\n",
    "    \"model__max_features\":[\"log2\",\"sqrt\"],\n",
    "    \"model__criterion\": [\"friedman_mse\",  \"mae\"],\n",
    "    \"model__subsample\":[0.5, 0.8, 0.9, 1.0],\n",
    "    \"model__n_estimators\":[10]\n",
    "    }\n",
    "\n",
    "optimised_final_pipeline = GridSearchCV(final_pipeline, hyper_params, cv=10, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8763796909492274, 0.910840108401084)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the GB with the selected hyper parameters, evaluate accuracy again\n",
    "optimised_final_pipeline.fit(X=X_train, y=y_train)\n",
    "optimised_final_pipeline.score(X=X_train, y=y_train), final_pipeline.score(X=X_test, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8763796909492274, 0.910840108401084)"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimised_final_pipeline.score(X=X_train, y=y_train), final_pipeline.score(X=X_test, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = optimised_final_pipeline.predict(X=X_test)\n",
    "cm = confusion_matrix(y_true=y_test, y_pred=pred)\n",
    "df_cm = pd.DataFrame(cm)\n",
    "df_cm.index.name = 'Actual Revenue'\n",
    "df_cm.columns.name = 'Predicted Revenue'\n",
    "sns.heatmap(df_cm, cmap=\"Blues\", annot=True, fmt='g', annot_kws={\"size\": 12});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['revenue_prediction_final_pipeline.joblib']"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(optimised_final_pipeline, 'revenue_prediction_final_pipeline.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store test data for expemlar http request\n",
    "X_test.iloc[25,:].to_json('test_instance_0.json')\n",
    "y_test.iloc[25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input_columns.joblib']"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = X_test.columns.tolist()\n",
    "dump(cols, 'input_columns.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## @ Thanh Ha: \n",
    "- es fehlt noch etwas narrative ich weiß..\n",
    "- mich beunruhigt, dass meine feature eng optionen keine wirkliche auswirkung haben\n",
    "- das gridsearch cv läuft ewigkeiten \n",
    "- das neural network performt nicht besser als die standard modelle -> ich glaube es liegt an der geringen datenmenge (NNs performen mit großen datenmengen besser), was denkst du? \n",
    "- Ich hab auch das Problem, dass man bei Keras die input_dim spezifizieren muss, aber durch die feature eng varianten (with_interaction) variiert diese...weißt du wie man das löst? X.shape[1] funktiniert hier nicht :/ \n",
    "- was würdest du ändern?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
